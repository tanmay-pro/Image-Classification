{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: SIFT-BoVW-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of SIFT detector and descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f89e4928d70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])  \n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cluster centres using bag of visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performSift(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    image = np.array(image)\n",
    "    keypoints = sift.detect(image, None)\n",
    "    keypoints, descriptors = sift.compute(image, keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def histogram_of_features(inpData, kmeans, n_clusters):\n",
    "    hist = []\n",
    "    for i in tqdm(range(len(inpData))):\n",
    "        image, label = inpData[i]\n",
    "        image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX). astype(np.uint8)\n",
    "        image = image.squeeze()\n",
    "        desc = performSift(image)\n",
    "        if desc is None:\n",
    "            hist.append(np.zeros(n_clusters))\n",
    "            continue\n",
    "        histogram = np.histogram(kmeans.predict(desc), bins=n_clusters, range=(0, n_clusters))[0]\n",
    "        hist.append(histogram)\n",
    "    return np.vstack(hist)\n",
    "\n",
    "def cluster_features(desc, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(desc)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear SVM for 10 way classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:42<00:00, 22.21it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.17it/s]\n"
     ]
    }
   ],
   "source": [
    "trainDesc = []\n",
    "testDesc = []\n",
    "for images, labels in tqdm(trainloader):\n",
    "    for image in images:\n",
    "        image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        image = image.squeeze()\n",
    "        desc = performSift(image)\n",
    "        if desc is not None:\n",
    "            trainDesc.append(desc)\n",
    "for images, labels in tqdm(testloader):\n",
    "    for image in images:\n",
    "        image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        image = image.squeeze()\n",
    "        desc = performSift(image)\n",
    "        if desc is not None:\n",
    "            testDesc.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469437, 128)\n"
     ]
    }
   ],
   "source": [
    "numClusters = 3\n",
    "\n",
    "traink = np.vstack(trainDesc)\n",
    "print(traink.shape)\n",
    "kmeans = cluster_features(traink, numClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:03<00:00, 938.01it/s] \n",
      "100%|██████████| 10000/10000 [00:10<00:00, 940.03it/s]\n"
     ]
    }
   ],
   "source": [
    "trainHist = histogram_of_features(trainset, kmeans, numClusters)\n",
    "testHist = histogram_of_features(testset, kmeans, numClusters)\n",
    "trainLabel = [label for _, label in trainset]\n",
    "testLabel = [label for _, label in testset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2506\n"
     ]
    }
   ],
   "source": [
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "svm_model.fit(trainHist, trainLabel)\n",
    "predicted = svm_model.predict(testHist)\n",
    "accuracy = accuracy_score(testLabel, predicted, normalize=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of classification accuracy with change in number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:07<00:00, 885.94it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 991.72it/s]\n",
      "100%|██████████| 60000/60000 [01:03<00:00, 950.94it/s] \n",
      "100%|██████████| 10000/10000 [00:09<00:00, 1003.03it/s]\n",
      "100%|██████████| 60000/60000 [01:04<00:00, 932.26it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 907.20it/s]\n",
      "100%|██████████| 60000/60000 [01:06<00:00, 902.26it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 888.94it/s]\n",
      "100%|██████████| 60000/60000 [01:01<00:00, 978.97it/s] \n",
      "100%|██████████| 10000/10000 [00:09<00:00, 1008.05it/s]\n",
      "100%|██████████| 60000/60000 [01:00<00:00, 994.04it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 979.60it/s]\n",
      "100%|██████████| 6/6 [1:54:45<00:00, 1147.61s/it]\n"
     ]
    }
   ],
   "source": [
    "clusterNums = [1, 3, 10, 30, 50, 100]\n",
    "accuracy = []\n",
    "for numClusters in tqdm(clusterNums):\n",
    "    kmeans = cluster_features(traink, numClusters)\n",
    "    trainHist = histogram_of_features(trainset, kmeans, numClusters)\n",
    "    testHist = histogram_of_features(testset, kmeans, numClusters)\n",
    "    svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "    svm_model.fit(trainHist, trainLabel)\n",
    "    predicted = svm_model.predict(testHist)\n",
    "    accuracy.append(accuracy_score(testLabel, predicted, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(clusterNums, accuracy)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters: 1, Accuracy: 0.2043\n",
      "Number of Clusters: 3, Accuracy: 0.2506\n",
      "Number of Clusters: 10, Accuracy: 0.4257\n",
      "Number of Clusters: 30, Accuracy: 0.598\n",
      "Number of Clusters: 50, Accuracy: 0.6713\n",
      "Number of Clusters: 100, Accuracy: 0.7529\n"
     ]
    }
   ],
   "source": [
    "for index, acc in enumerate(accuracy):\n",
    "    print(f'Number of Clusters: {clusterNums[index]}, Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the increase in number of clusters, the classification accuracy increases. This is because with the increase in number of clusters, each cluster becomes more specific to certain visual patterns or features within the images. This then enables better discrimination between different classes, as the histogram of visual words capture more detailed information. \n",
    "- There is a maximum optimal number of clusters after which the accuracy will stop increasing (cas we can see from the concave down shape of the graph). The accuracy might even start decreasing beyond this optimal number, due to increased complexity and overfitting.\n",
    "- Among my selection, 100 clusters presents the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Visualization for different hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performSiftHyp(image, numFeatures, thresh):\n",
    "    sift = cv2.SIFT_create(nfeatures=numFeatures, contrastThreshold=thresh)\n",
    "    image = np.array(image)\n",
    "    keypoints = sift.detect(image, None)\n",
    "    keypoints, descriptors = sift.compute(image, keypoints)\n",
    "    return descriptors\n",
    "\n",
    "def histogram_of_featuresHyp(inpData, kmeans, n_clusters, numFeatures, thresh):\n",
    "    hist = []\n",
    "    for i in tqdm(range(len(inpData))):\n",
    "        image, label = inpData[i]\n",
    "        image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX). astype(np.uint8)\n",
    "        image = image.squeeze()\n",
    "        desc = performSiftHyp(image, numFeatures, thresh)\n",
    "        if desc is None:\n",
    "            hist.append(np.zeros(n_clusters))\n",
    "            continue\n",
    "        histogram = np.histogram(kmeans.predict(desc), bins=n_clusters, range=(0, n_clusters))[0]\n",
    "        hist.append(histogram)\n",
    "    return np.vstack(hist)\n",
    "\n",
    "def cluster_featuresHyp(desc, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(desc)\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "def getAccuracy(numClusters, trainset, testset, c, numFeatures, thresh):\n",
    "    trainDesc = []\n",
    "    testDesc = []\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        for image in images:\n",
    "            image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            image = image.squeeze()\n",
    "            desc = performSiftHyp(image, numFeatures, thresh)\n",
    "            if desc is not None:\n",
    "                trainDesc.append(desc)\n",
    "    for images, labels in tqdm(testloader):\n",
    "        for image in images:\n",
    "            image = cv2.normalize(image.numpy(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            image = image.squeeze()\n",
    "            desc = performSiftHyp(image, numFeatures, thresh)\n",
    "            if desc is not None:\n",
    "                testDesc.append(desc)\n",
    "    traink = np.vstack(trainDesc)\n",
    "    kmeans = cluster_featuresHyp(traink, numClusters)\n",
    "    trainHist = histogram_of_featuresHyp(trainset, kmeans, numClusters, numFeatures, thresh)\n",
    "    testHist = histogram_of_featuresHyp(testset, kmeans, numClusters, numFeatures, thresh)\n",
    "    trainLabel = [label for _, label in trainset]\n",
    "    testLabel = [label for _, label in testset]\n",
    "    svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=c))\n",
    "    svm_model.fit(trainHist, trainLabel)\n",
    "    predicted = svm_model.predict(testHist)\n",
    "    return accuracy_score(testLabel, predicted, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:43<00:00, 21.52it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.93it/s]\n",
      "100%|██████████| 60000/60000 [01:04<00:00, 923.48it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 925.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 0.1, nFeatures = 100, constThreshold = 0.02, the accuracy is: 0.7475\n"
     ]
    }
   ],
   "source": [
    "numClusters = 100\n",
    "c = 0.1\n",
    "nFeatures = 100\n",
    "constThreshold = 0.02\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:42<00:00, 21.81it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.99it/s]\n",
      "100%|██████████| 60000/60000 [01:04<00:00, 931.48it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 899.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 1, nFeatures = 200, constThreshold = 0.04, the accuracy is: 0.7526\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "nFeatures = 200\n",
    "constThreshold = 0.04\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:43<00:00, 21.80it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.83it/s]\n",
      "100%|██████████| 60000/60000 [01:05<00:00, 917.30it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 947.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 10, nFeatures = 300, constThreshold = 0.06, the accuracy is: 0.7521\n"
     ]
    }
   ],
   "source": [
    "c = 10\n",
    "nFeatures = 300\n",
    "constThreshold = 0.06\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:42<00:00, 21.84it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.35it/s]\n",
      "100%|██████████| 60000/60000 [01:02<00:00, 966.13it/s] \n",
      "100%|██████████| 10000/10000 [00:10<00:00, 960.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 0.1, nFeatures = 150, constThreshold = 0.03, the accuracy is: 0.7499\n"
     ]
    }
   ],
   "source": [
    "c = 0.1\n",
    "nFeatures = 150\n",
    "constThreshold = 0.03\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:41<00:00, 22.38it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.95it/s]\n",
      "100%|██████████| 60000/60000 [01:04<00:00, 926.04it/s] \n",
      "100%|██████████| 10000/10000 [00:10<00:00, 948.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 1, nFeatures = 250, constThreshold = 0.05, the accuracy is: 0.7475\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "nFeatures = 250\n",
    "constThreshold = 0.05\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:43<00:00, 21.58it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.05it/s]\n",
      "100%|██████████| 60000/60000 [01:06<00:00, 895.78it/s]\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 901.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the parameters: numClusters = 100, c = 10, nFeatures = 350, constThreshold = 0.07, the accuracy is: 0.756\n"
     ]
    }
   ],
   "source": [
    "c = 10\n",
    "nFeatures = 350\n",
    "constThreshold = 0.07\n",
    "accuracy = getAccuracy(numClusters, trainset, testset, c, nFeatures, constThreshold)\n",
    "print(\"For the parameters: numClusters = {}, c = {}, nFeatures = {}, constThreshold = {}, the accuracy is: {}\".format(numClusters, c, nFeatures, constThreshold, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With increase in the regularization parameter (C), the accuracy values gradually increase as we can see from our observations. Accuracy values range from approximately 0.7475 to 0.756, indicating that changing C within the given range does not significantly impact classification performance.\n",
    "- There's a slight variation in accuracy when changing the number of SIFT features. The highest accuracy (0.756) is achieved with a higher number of features (nFeatures = 350), while lower accuracies are observed with fewer features.\n",
    "- Overall, the observed trends suggest that the choice of SVM regularization parameter (C) and the number of SIFT features (nFeatures) have a relatively modest impact on classification accuracy, while variations in SIFT descriptor parameters (constThreshold) seem to have minimal effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: CNNs and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LeNet for performing classification on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"MNIST\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(leNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoaders(train_dataset, test_dataset, batch_size):\n",
    "    trainSize = int(0.9 * len(train_dataset))\n",
    "    valSize = len(train_dataset) - trainSize\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [trainSize, valSize])\n",
    "    trainLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    testLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return trainLoader, valLoader, testLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, trainLoader, valLoader, device):\n",
    "    \n",
    "    trainingLosses = []\n",
    "    validationLosses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainLoader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(i)\n",
    "            # if i % 400 == 399:\n",
    "            #     print(f'[{epoch + 1}, {i + 1}] Training loss: {running_loss / 400}')\n",
    "            #     running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0.0\n",
    "            for data in valLoader:\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print(f'[{epoch + 1}] Training loss: {running_loss / len(trainLoader)}')\n",
    "            print(f'[{epoch + 1}] Validation Accuracy: {100 * correct / total}')\n",
    "            wandb.log({'loss': loss / len(valLoader), 'accuracy': 100 * correct / total})\n",
    "            print(f'[{epoch + 1}] Validation loss: {loss / len(valLoader)}')\n",
    "            validationLosses.append(loss / len(valLoader))\n",
    "            trainingLosses.append(running_loss / len(trainLoader))\n",
    "\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "    print('Finished Training')\n",
    "    return trainingLosses, validationLosses\n",
    "\n",
    "\n",
    "def test(model, testLoader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        wandb.log({'test_accuracy': 100 * correct / total})\n",
    "        print('Accuracy of the network on the {} test images: {:.1f}'.format(total, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = leNet()\n",
    "model = model.to(device)\n",
    "# device = torch.device('cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.27493185139817333\n",
      "[1] Validation Accuracy: 97.58333333333333\n",
      "[1] Validation loss: 0.08424770894480195\n",
      "[2] Training loss: 0.07516877019614582\n",
      "[2] Validation Accuracy: 97.91666666666667\n",
      "[2] Validation loss: 0.06981120870369388\n",
      "[3] Training loss: 0.05413597133214766\n",
      "[3] Validation Accuracy: 98.16666666666667\n",
      "[3] Validation loss: 0.058621732364507746\n",
      "[4] Training loss: 0.041648425441221514\n",
      "[4] Validation Accuracy: 98.16666666666667\n",
      "[4] Validation loss: 0.0667716283475029\n",
      "[5] Training loss: 0.03613792669964056\n",
      "[5] Validation Accuracy: 98.31666666666666\n",
      "[5] Validation loss: 0.05257486752135322\n",
      "[6] Training loss: 0.029230888686974595\n",
      "[6] Validation Accuracy: 98.55\n",
      "[6] Validation loss: 0.04678638338141064\n",
      "[7] Training loss: 0.02618330423639835\n",
      "[7] Validation Accuracy: 98.7\n",
      "[7] Validation loss: 0.04834337306501185\n",
      "[8] Training loss: 0.02077450756945259\n",
      "[8] Validation Accuracy: 98.66666666666667\n",
      "[8] Validation loss: 0.04906638457899309\n",
      "[9] Training loss: 0.019708646185407085\n",
      "[9] Validation Accuracy: 98.45\n",
      "[9] Validation loss: 0.05565284324984532\n",
      "[10] Training loss: 0.018228067515092206\n",
      "[10] Validation Accuracy: 98.65\n",
      "[10] Validation loss: 0.05033082688091684\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.8\n"
     ]
    }
   ],
   "source": [
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "trainingLoss, validationLoss = train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainingLoss, label='Training Loss')\n",
    "plt.plot(validationLoss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results for various hyperparameter settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.010059480877980745\n",
      "[1] Validation Accuracy: 99.75\n",
      "[1] Validation loss: 0.008006093293904493\n",
      "[2] Training loss: 0.006368298794372145\n",
      "[2] Validation Accuracy: 99.81666666666666\n",
      "[2] Validation loss: 0.008291937135919745\n",
      "[3] Training loss: 0.0045336443455921\n",
      "[3] Validation Accuracy: 99.76666666666667\n",
      "[3] Validation loss: 0.008307385548443727\n",
      "[4] Training loss: 0.0035292415351579117\n",
      "[4] Validation Accuracy: 99.8\n",
      "[4] Validation loss: 0.009411695943793243\n",
      "[5] Training loss: 0.0028277333228167193\n",
      "[5] Validation Accuracy: 99.78333333333333\n",
      "[5] Validation loss: 0.00857433715595114\n",
      "[6] Training loss: 0.0021762745548485137\n",
      "[6] Validation Accuracy: 99.75\n",
      "[6] Validation loss: 0.01132240623558197\n",
      "[7] Training loss: 0.001624039630828898\n",
      "[7] Validation Accuracy: 99.75\n",
      "[7] Validation loss: 0.009618476274064936\n",
      "[8] Training loss: 0.0013026447143218917\n",
      "[8] Validation Accuracy: 99.73333333333333\n",
      "[8] Validation loss: 0.010569205352773753\n",
      "[9] Training loss: 0.0011068533626134368\n",
      "[9] Validation Accuracy: 99.7\n",
      "[9] Validation loss: 0.011531707434968385\n",
      "[10] Training loss: 0.0008912324131726011\n",
      "[10] Validation Accuracy: 99.75\n",
      "[10] Validation loss: 0.012092525412269201\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.007322144390985676\n",
      "[1] Validation Accuracy: 99.16666666666667\n",
      "[1] Validation loss: 0.030602307057264664\n",
      "[2] Training loss: 0.006231511368036748\n",
      "[2] Validation Accuracy: 99.61666666666666\n",
      "[2] Validation loss: 0.012628216729044265\n",
      "[3] Training loss: 0.004182835416182189\n",
      "[3] Validation Accuracy: 99.76666666666667\n",
      "[3] Validation loss: 0.00864944054330621\n",
      "[4] Training loss: 0.003701029500291228\n",
      "[4] Validation Accuracy: 99.63333333333334\n",
      "[4] Validation loss: 0.011728889576556384\n",
      "[5] Training loss: 0.002784419491312395\n",
      "[5] Validation Accuracy: 99.76666666666667\n",
      "[5] Validation loss: 0.008480243996833703\n",
      "[6] Training loss: 0.0015463701531554653\n",
      "[6] Validation Accuracy: 99.8\n",
      "[6] Validation loss: 0.009461053768065459\n",
      "[7] Training loss: 0.0010377883531050337\n",
      "[7] Validation Accuracy: 99.85\n",
      "[7] Validation loss: 0.00801270672303705\n",
      "[8] Training loss: 0.0005316339902588931\n",
      "[8] Validation Accuracy: 99.88333333333334\n",
      "[8] Validation loss: 0.006870295750592265\n",
      "[9] Training loss: 0.00041975597415481954\n",
      "[9] Validation Accuracy: 99.85\n",
      "[9] Validation loss: 0.008764311693507588\n",
      "[10] Training loss: 0.0006369532610319316\n",
      "[10] Validation Accuracy: 99.85\n",
      "[10] Validation loss: 0.008075835227032107\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "lr = 0.1\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.009428337525396402\n",
      "[1] Validation Accuracy: 99.68333333333334\n",
      "[1] Validation loss: 0.008117626030264334\n",
      "[2] Training loss: 0.0073185321372360385\n",
      "[2] Validation Accuracy: 99.3\n",
      "[2] Validation loss: 0.021925993931832404\n",
      "[3] Training loss: 0.005838900316914651\n",
      "[3] Validation Accuracy: 99.45\n",
      "[3] Validation loss: 0.017236928757957938\n",
      "[4] Training loss: 0.009828248631059702\n",
      "[4] Validation Accuracy: 99.58333333333333\n",
      "[4] Validation loss: 0.012368442235264352\n",
      "[5] Training loss: 0.004359366406071864\n",
      "[5] Validation Accuracy: 99.7\n",
      "[5] Validation loss: 0.00961136930976515\n",
      "[6] Training loss: 0.006565598693311254\n",
      "[6] Validation Accuracy: 99.6\n",
      "[6] Validation loss: 0.012946556965463506\n",
      "[7] Training loss: 0.005584776523731509\n",
      "[7] Validation Accuracy: 99.75\n",
      "[7] Validation loss: 0.009457099502411593\n",
      "[8] Training loss: 0.004441795915062642\n",
      "[8] Validation Accuracy: 99.33333333333333\n",
      "[8] Validation loss: 0.02455222815213811\n",
      "[9] Training loss: 0.005580191421671139\n",
      "[9] Validation Accuracy: 99.61666666666666\n",
      "[9] Validation loss: 0.014727440299213142\n",
      "[10] Training loss: 0.005147125582273957\n",
      "[10] Validation Accuracy: 99.68333333333334\n",
      "[10] Validation loss: 0.01341932893431844\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.0018548704160979478\n",
      "[1] Validation Accuracy: 99.98333333333333\n",
      "[1] Validation loss: 0.0004584345503718502\n",
      "[2] Training loss: 0.0006294516433323289\n",
      "[2] Validation Accuracy: 99.98333333333333\n",
      "[2] Validation loss: 0.0005469121130170318\n",
      "[3] Training loss: 0.00027335202181524393\n",
      "[3] Validation Accuracy: 99.98333333333333\n",
      "[3] Validation loss: 0.0005508597227082991\n",
      "[4] Training loss: 0.00014668098978299097\n",
      "[4] Validation Accuracy: 99.98333333333333\n",
      "[4] Validation loss: 0.0006774327507044233\n",
      "[5] Training loss: 8.782699400598406e-05\n",
      "[5] Validation Accuracy: 99.96666666666667\n",
      "[5] Validation loss: 0.0005238630351326276\n",
      "[6] Training loss: 4.755531784539726e-05\n",
      "[6] Validation Accuracy: 99.96666666666667\n",
      "[6] Validation loss: 0.001067224011076667\n",
      "[7] Training loss: 2.185204278161507e-05\n",
      "[7] Validation Accuracy: 99.98333333333333\n",
      "[7] Validation loss: 0.0007904488377787238\n",
      "[8] Training loss: 2.008926119628155e-05\n",
      "[8] Validation Accuracy: 99.98333333333333\n",
      "[8] Validation loss: 0.0007901115920513807\n",
      "[9] Training loss: 8.32594393929776e-06\n",
      "[9] Validation Accuracy: 99.98333333333333\n",
      "[9] Validation loss: 0.0009340076482466883\n",
      "[10] Training loss: 1.633089557475314e-05\n",
      "[10] Validation Accuracy: 99.98333333333333\n",
      "[10] Validation loss: 0.0006929138834230056\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99.2\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.2787163868390508\n",
      "[1] Validation Accuracy: 94.1\n",
      "[1] Validation loss: 0.20534059279003836\n",
      "[2] Training loss: 0.11315503026201126\n",
      "[2] Validation Accuracy: 97.2\n",
      "[2] Validation loss: 0.0936748483082796\n",
      "[3] Training loss: 0.06659987114121728\n",
      "[3] Validation Accuracy: 98.13333333333334\n",
      "[3] Validation loss: 0.05724800653564323\n",
      "[4] Training loss: 0.04937244976342571\n",
      "[4] Validation Accuracy: 97.91666666666667\n",
      "[4] Validation loss: 0.07865862154768423\n",
      "[5] Training loss: 0.04101372938448678\n",
      "[5] Validation Accuracy: 98.55\n",
      "[5] Validation loss: 0.055193708434865374\n",
      "[6] Training loss: 0.037551344413796005\n",
      "[6] Validation Accuracy: 98.55\n",
      "[6] Validation loss: 0.05512323975003807\n",
      "[7] Training loss: 0.032213570556697345\n",
      "[7] Validation Accuracy: 98.5\n",
      "[7] Validation loss: 0.05646957797828091\n",
      "[8] Training loss: 0.027087716128681473\n",
      "[8] Validation Accuracy: 98.66666666666667\n",
      "[8] Validation loss: 0.05375227092002767\n",
      "[9] Training loss: 0.02442239491975019\n",
      "[9] Validation Accuracy: 98.73333333333333\n",
      "[9] Validation loss: 0.052517572075653045\n",
      "[10] Training loss: 0.023651603093078306\n",
      "[10] Validation Accuracy: 98.75\n",
      "[10] Validation loss: 0.052166272303972444\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr = 0.1\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.015333621001682935\n",
      "[1] Validation Accuracy: 99.63333333333334\n",
      "[1] Validation loss: 0.01161792690517688\n",
      "[2] Training loss: 0.009434876941478678\n",
      "[2] Validation Accuracy: 99.66666666666667\n",
      "[2] Validation loss: 0.0118786794659211\n",
      "[3] Training loss: 0.006211305291264873\n",
      "[3] Validation Accuracy: 99.53333333333333\n",
      "[3] Validation loss: 0.013985729745670935\n",
      "[4] Training loss: 0.0052621198197096665\n",
      "[4] Validation Accuracy: 99.66666666666667\n",
      "[4] Validation loss: 0.011535164685889693\n",
      "[5] Training loss: 0.00682968198292811\n",
      "[5] Validation Accuracy: 99.36666666666666\n",
      "[5] Validation loss: 0.02319845313050269\n",
      "[6] Training loss: 0.005061433625988249\n",
      "[6] Validation Accuracy: 99.51666666666667\n",
      "[6] Validation loss: 0.01813293851638322\n",
      "[7] Training loss: 0.0032777174901434483\n",
      "[7] Validation Accuracy: 99.56666666666666\n",
      "[7] Validation loss: 0.015574321479049259\n",
      "[8] Training loss: 0.0025395643652642336\n",
      "[8] Validation Accuracy: 99.3\n",
      "[8] Validation loss: 0.024316813376920418\n",
      "[9] Training loss: 0.004135977131810246\n",
      "[9] Validation Accuracy: 99.53333333333333\n",
      "[9] Validation loss: 0.018487690908977072\n",
      "[10] Training loss: 0.0037565138028719663\n",
      "[10] Validation Accuracy: 99.3\n",
      "[10] Validation loss: 0.028070029172243827\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 10\n",
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model, testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Higher batch sizes (e.g., 128) generally lead to faster convergence and smoother training curves compared to smaller batch sizes (e.g., 32 or 64). In our observations, batch sizes of 32, 64, and 128 all achieve high accuracies, but the convergence patterns and final accuracy levels may vary. However, excessively large batch sizes might cause the model to converge to suboptimal solutions or even diverge due to decreased stochasticity in gradient updates.\n",
    "- A learning rate that is too low may result in slow convergence, while a learning rate that is too high can lead to unstable training and poor generalization. Learning rates of 0.0001 and 0.001 generally result in smoother training curves and higher final accuracies compared to a learning rate of 0.1, which exhibits more erratic behavior.\n",
    "- According to our observations, optimizers like Adam and RMSprop tend to converge faster and achieve higher accuracies compared to SGD with momentum.\n",
    "- Learning rate and optimizer choice have a more significant impact on classification accuracy compared to batch size.\n",
    "- Models trained with lower learning rates (e.g., 0.0001 or 0.001) using optimizers like Adam or RMSprop tend to achieve higher accuracies and more stable convergence behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the best performing CNN against the SIFT-BoVW-SVM approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracies obtained by our CNN models is much higher as compared to those obtained through SIFT-BoVW-SVM approach. \n",
    "- CNN models automatically learn hierarchical features from raw pixel values through multiple layers of convolutions, pooling, and non-linear activations. They data-driven and capable of learning intricate patterns directly from the images, which can lead to highly discriminative representations for classification tasks. In contrast, the SIFT-BoVW-SVM approach involves a handcrafted feature extraction pipeline. Scale-Invariant Feature Transform (SIFT) features are extracted from images, and then a Bag-of-Visual-Words (BoVW) model is used to represent each image as a histogram of visual words. While SIFT features are robust to variations in scale and rotation, they are less adaptive compared to features learned by CNNs.\n",
    "- CNNs learn feature representations in an end-to-end manner, optimizing both feature extraction and classification jointly during training. The SIFT-BoVW-SVM approach relies on handcrafted feature descriptors and a predefined pipeline for feature extraction and classification (unable to capture the full complexity).\n",
    "- CNNs require a large amount of labeled training data and computational resources for training. However, once trained, they can efficiently classify new images. The SIFT-BoVW-SVM approach is computationally expensive during both feature extraction and training. Additionally, the performance of the BoVW model heavily depends on the choice of parameters such as the number of clusters (visual words). As the number of clusters increases, the dimensionality of the feature space grows, which may lead to increased computational complexity and memory requirements. The SIFT-BoVW-SVM approach becomes extremely slow with the increase in number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in performance with increase in number of convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(leNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv12 = nn.Conv2d(6, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv22 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*1*1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv12(F.relu(self.conv1(x)))))\n",
    "        x = self.pool(F.relu(self.conv22(F.relu(self.conv2(x)))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = leNet2()\n",
    "model2 = model2.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 0.3873025266480107\n",
      "[1] Validation Accuracy: 95.33333333333333\n",
      "[1] Validation loss: 0.14703472275683221\n",
      "[2] Training loss: 0.11445595328894695\n",
      "[2] Validation Accuracy: 97.1\n",
      "[2] Validation loss: 0.08149114495856648\n",
      "[3] Training loss: 0.0815191919130816\n",
      "[3] Validation Accuracy: 97.61666666666666\n",
      "[3] Validation loss: 0.07671488789306517\n",
      "[4] Training loss: 0.06426801128336118\n",
      "[4] Validation Accuracy: 98.11666666666666\n",
      "[4] Validation loss: 0.05597338118550784\n",
      "[5] Training loss: 0.055721871849338155\n",
      "[5] Validation Accuracy: 98.11666666666666\n",
      "[5] Validation loss: 0.059553718162165516\n",
      "[6] Training loss: 0.04780875479814076\n",
      "[6] Validation Accuracy: 98.71666666666667\n",
      "[6] Validation loss: 0.04263108348761229\n",
      "[7] Training loss: 0.0426805719493373\n",
      "[7] Validation Accuracy: 98.56666666666666\n",
      "[7] Validation loss: 0.04601701566617579\n",
      "[8] Training loss: 0.03866735669370863\n",
      "[8] Validation Accuracy: 98.08333333333333\n",
      "[8] Validation loss: 0.06398343180425148\n",
      "[9] Training loss: 0.034174581251291435\n",
      "[9] Validation Accuracy: 98.8\n",
      "[9] Validation loss: 0.042260856125528545\n",
      "[10] Training loss: 0.03205054043890465\n",
      "[10] Validation Accuracy: 98.26666666666667\n",
      "[10] Validation loss: 0.05909735359966091\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.6\n"
     ]
    }
   ],
   "source": [
    "trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size)\n",
    "train(model2, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model2, testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original LeNet:\n",
    "    - Testing accuracy: 98.8%\n",
    "    - Final Validation loss: 0.05033082688091684\n",
    "\n",
    "- Double Convolutional Layers:\n",
    "    - Testing accuracy: 98.6%\n",
    "    - Final Validation loss: 0.05909735359966091\n",
    "\n",
    "- Increasing the number of convolutional layers increases the model's complexity and capacity to learn intricate patterns in the data. However, this increased complexity may not always lead to improved performance. It leads to faster convergence if you have double number of convolutional layers. However, it might be more prone to overfitting as compared to the original model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in performance with varying dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoaders(train_dataset, test_dataset, batch_size, dataLen):\n",
    "    # trainSize = int(0.9 * len(train_dataset))\n",
    "    trainSize = int(0.9 * dataLen)\n",
    "    valSize = dataLen - trainSize\n",
    "    wasteSize = len(train_dataset) - dataLen\n",
    "    train_dataset, val_dataset, waste_dataset = random_split(train_dataset, [trainSize, valSize, wasteSize])\n",
    "    trainLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    testLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return trainLoader, valLoader, testLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 600\n",
      "[1] Training loss: 2.2984461784362793\n",
      "[1] Validation Accuracy: 16.666666666666668\n",
      "[1] Validation loss: 2.287897825241089\n",
      "[2] Training loss: 2.285604821311103\n",
      "[2] Validation Accuracy: 16.666666666666668\n",
      "[2] Validation loss: 2.2673768997192383\n",
      "[3] Training loss: 2.2353653642866345\n",
      "[3] Validation Accuracy: 33.333333333333336\n",
      "[3] Validation loss: 2.161525249481201\n",
      "[4] Training loss: 2.027209851476881\n",
      "[4] Validation Accuracy: 35.0\n",
      "[4] Validation loss: 1.8264175653457642\n",
      "[5] Training loss: 1.6203526258468628\n",
      "[5] Validation Accuracy: 51.666666666666664\n",
      "[5] Validation loss: 1.5834287405014038\n",
      "[6] Training loss: 1.1757380565007527\n",
      "[6] Validation Accuracy: 56.666666666666664\n",
      "[6] Validation loss: 1.3060276508331299\n",
      "[7] Training loss: 0.9148714741071066\n",
      "[7] Validation Accuracy: 56.666666666666664\n",
      "[7] Validation loss: 1.0620474815368652\n",
      "[8] Training loss: 0.7923381659719679\n",
      "[8] Validation Accuracy: 65.0\n",
      "[8] Validation loss: 0.8983908295631409\n",
      "[9] Training loss: 0.715630269712872\n",
      "[9] Validation Accuracy: 65.0\n",
      "[9] Validation loss: 0.9344613552093506\n",
      "[10] Training loss: 0.6783010628488328\n",
      "[10] Validation Accuracy: 75.0\n",
      "[10] Validation loss: 0.7281205058097839\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 74.3\n",
      "Length of data: 1800\n",
      "[1] Training loss: 2.2876967650193434\n",
      "[1] Validation Accuracy: 20.0\n",
      "[1] Validation loss: 2.2269110679626465\n",
      "[2] Training loss: 1.7878325306452238\n",
      "[2] Validation Accuracy: 58.333333333333336\n",
      "[2] Validation loss: 1.2273447513580322\n",
      "[3] Training loss: 0.9042761749946154\n",
      "[3] Validation Accuracy: 73.88888888888889\n",
      "[3] Validation loss: 0.763527492682139\n",
      "[4] Training loss: 0.6261049027626331\n",
      "[4] Validation Accuracy: 78.33333333333333\n",
      "[4] Validation loss: 0.6324946085611979\n",
      "[5] Training loss: 0.5237534573444953\n",
      "[5] Validation Accuracy: 80.0\n",
      "[5] Validation loss: 0.5876050988833109\n",
      "[6] Training loss: 0.4486125839444307\n",
      "[6] Validation Accuracy: 82.77777777777777\n",
      "[6] Validation loss: 0.5013639330863953\n",
      "[7] Training loss: 0.3505858455139857\n",
      "[7] Validation Accuracy: 87.77777777777777\n",
      "[7] Validation loss: 0.3645630379517873\n",
      "[8] Training loss: 0.3229488782011546\n",
      "[8] Validation Accuracy: 88.33333333333333\n",
      "[8] Validation loss: 0.3665521244208018\n",
      "[9] Training loss: 0.2763915437345321\n",
      "[9] Validation Accuracy: 88.33333333333333\n",
      "[9] Validation loss: 0.3840641776720683\n",
      "[10] Training loss: 0.23799389199568674\n",
      "[10] Validation Accuracy: 91.11111111111111\n",
      "[10] Validation loss: 0.36095717549324036\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 89.5\n",
      "Length of data: 6000\n",
      "[1] Training loss: 1.59757218431024\n",
      "[1] Validation Accuracy: 73.5\n",
      "[1] Validation loss: 0.7290310561656952\n",
      "[2] Training loss: 0.6274604963905671\n",
      "[2] Validation Accuracy: 86.0\n",
      "[2] Validation loss: 0.4117923125624657\n",
      "[3] Training loss: 0.3702366473043666\n",
      "[3] Validation Accuracy: 89.5\n",
      "[3] Validation loss: 0.30213361978530884\n",
      "[4] Training loss: 0.2783691017066731\n",
      "[4] Validation Accuracy: 92.5\n",
      "[4] Validation loss: 0.22407407462596893\n",
      "[5] Training loss: 0.22583194979849983\n",
      "[5] Validation Accuracy: 93.33333333333333\n",
      "[5] Validation loss: 0.17425687089562417\n",
      "[6] Training loss: 0.18503523341873113\n",
      "[6] Validation Accuracy: 96.16666666666667\n",
      "[6] Validation loss: 0.12984784841537475\n",
      "[7] Training loss: 0.1544616246048142\n",
      "[7] Validation Accuracy: 94.33333333333333\n",
      "[7] Validation loss: 0.1673831580206752\n",
      "[8] Training loss: 0.14034614107188056\n",
      "[8] Validation Accuracy: 94.33333333333333\n",
      "[8] Validation loss: 0.16225223764777183\n",
      "[9] Training loss: 0.11950629239573199\n",
      "[9] Validation Accuracy: 96.16666666666667\n",
      "[9] Validation loss: 0.10840071067214012\n",
      "[10] Training loss: 0.10252927253570626\n",
      "[10] Validation Accuracy: 96.33333333333333\n",
      "[10] Validation loss: 0.10642522349953651\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 95.9\n",
      "Length of data: 18000\n",
      "[1] Training loss: 0.7646651515575844\n",
      "[1] Validation Accuracy: 91.33333333333333\n",
      "[1] Validation loss: 0.2591380405014959\n",
      "[2] Training loss: 0.22080064672008742\n",
      "[2] Validation Accuracy: 95.77777777777777\n",
      "[2] Validation loss: 0.14444869869099608\n",
      "[3] Training loss: 0.14786775876569935\n",
      "[3] Validation Accuracy: 95.77777777777777\n",
      "[3] Validation loss: 0.13548365877620105\n",
      "[4] Training loss: 0.11004767120691149\n",
      "[4] Validation Accuracy: 97.38888888888889\n",
      "[4] Validation loss: 0.08355971037185397\n",
      "[5] Training loss: 0.08676824045521538\n",
      "[5] Validation Accuracy: 97.77777777777777\n",
      "[5] Validation loss: 0.10305393587573078\n",
      "[6] Training loss: 0.07603851836688054\n",
      "[6] Validation Accuracy: 97.61111111111111\n",
      "[6] Validation loss: 0.07177408032344076\n",
      "[7] Training loss: 0.062246177384013855\n",
      "[7] Validation Accuracy: 98.16666666666667\n",
      "[7] Validation loss: 0.06798584674131768\n",
      "[8] Training loss: 0.053204939931202094\n",
      "[8] Validation Accuracy: 98.27777777777777\n",
      "[8] Validation loss: 0.05860753306428548\n",
      "[9] Training loss: 0.04788251664062346\n",
      "[9] Validation Accuracy: 98.38888888888889\n",
      "[9] Validation loss: 0.060148923786292816\n",
      "[10] Training loss: 0.04040393899100939\n",
      "[10] Validation Accuracy: 98.55555555555556\n",
      "[10] Validation loss: 0.05188921030414098\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.0\n",
      "Length of data: 60000\n",
      "[1] Training loss: 0.321739318308319\n",
      "[1] Validation Accuracy: 96.86666666666666\n",
      "[1] Validation loss: 0.08937395299646131\n",
      "[2] Training loss: 0.0870715104003759\n",
      "[2] Validation Accuracy: 98.01666666666667\n",
      "[2] Validation loss: 0.06588912880583171\n",
      "[3] Training loss: 0.06348205254298979\n",
      "[3] Validation Accuracy: 98.31666666666666\n",
      "[3] Validation loss: 0.049725475562538236\n",
      "[4] Training loss: 0.05399810079685456\n",
      "[4] Validation Accuracy: 98.1\n",
      "[4] Validation loss: 0.058983581286775784\n",
      "[5] Training loss: 0.04532600226733443\n",
      "[5] Validation Accuracy: 98.53333333333333\n",
      "[5] Validation loss: 0.048561876121427906\n",
      "[6] Training loss: 0.04188452399665047\n",
      "[6] Validation Accuracy: 98.5\n",
      "[6] Validation loss: 0.05028861940793812\n",
      "[7] Training loss: 0.037282329006651606\n",
      "[7] Validation Accuracy: 98.45\n",
      "[7] Validation loss: 0.0476160833291323\n",
      "[8] Training loss: 0.03386293527983588\n",
      "[8] Validation Accuracy: 98.68333333333334\n",
      "[8] Validation loss: 0.04640251390098475\n",
      "[9] Training loss: 0.030865622952725144\n",
      "[9] Validation Accuracy: 98.71666666666667\n",
      "[9] Validation loss: 0.04200574529370878\n",
      "[10] Training loss: 0.02649949713989014\n",
      "[10] Validation Accuracy: 98.81666666666666\n",
      "[10] Validation loss: 0.03836382859902942\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 98.9\n"
     ]
    }
   ],
   "source": [
    "lenData = [600, 1800, 6000, 18000, 60000]\n",
    "\n",
    "for dataLen in lenData:\n",
    "    model = leNet()\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(f'Length of data: {dataLen}')\n",
    "    trainLoader, valLoader, testLoader = dataLoaders(train_dataset, test_dataset, batch_size, dataLen)\n",
    "    train(model, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "    test(model, testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our accuracy increases from 75% to 99% with increase in the amount of data being used for processing.\n",
    "- More data provides the model with a better understanding of the underlying patterns in the dataset, leading to higher accuracy.\n",
    "- When number of sample is 600: The model's performance is relatively low with a small dataset. With limited data, the model struggles to capture the underlying patterns in the dataset, resulting in lower accuracy.\n",
    "- With a substantial increase in training data to 60,000 samples, we observe the highest accuracy achieved by the model. The abundance of training examples allows the model to capture a wide range of variations in the data, resulting in superior performance.\n",
    "- With a larger dataset, the model can generalize better to unseen examples. It learns to extract relevant features and patterns that are more representative of the entire dataset, rather than memorizing specific instances from a smaller dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a 2 layer TransformerEncoder and evaluate classification accuracies on varying dataset sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "class ViT(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, nhead):\n",
    "        super(ViT, self).__init__()\n",
    "        self.patchSize = 7\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nhead = nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.patchDim = self.patchSize**2\n",
    "        self.patchesNum = (28//self.patchSize)**2\n",
    "        self.posEmbed = nn.Parameter(torch.randn(1, self.patchesNum + 1, hidden_dim))\n",
    "        self.projection = nn.Linear(self.patchDim, hidden_dim)\n",
    "        self.tokens = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        patchSize = self.patchSize\n",
    "        x = x.unfold(2, patchSize, patchSize).unfold(3, patchSize, patchSize)\n",
    "        x = x.contiguous().view(batch_size, channels, -1, patchSize, patchSize)\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = x.reshape(batch_size, -1, channels*patchSize*patchSize)\n",
    "        x = self.projection(x)\n",
    "        x = torch.cat((self.tokens.expand(batch_size, -1, -1), x), dim=1)\n",
    "        x += self.posEmbed\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, 0, :]\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainSize = int(0.9 * len(trainset))\n",
    "valSize = len(trainset) - trainSize\n",
    "train_dataset, val_dataset = random_split(trainset, [trainSize, valSize])\n",
    "trainLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testLoader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 16\n",
    "hiddenDim = 64\n",
    "outputDim = 10\n",
    "numLayers = 2\n",
    "nhead = 4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model3 = ViT(inputDim, hiddenDim, outputDim, numLayers, nhead)\n",
    "model3 = model3.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, trainLoader, valLoader, device):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainLoader, 0):\n",
    "            inputs, labels = data\n",
    "            # inputs = inputs.view(-1, inputDim)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 400 == 399:\n",
    "                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 1000}')\n",
    "                running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0.0\n",
    "            for data in valLoader:\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print(f'[{epoch + 1}] loss: {loss / len(valLoader)}')\n",
    "        print(\"Validation Accuracy: \", 100 * correct / total)\n",
    "    torch.save(model.state_dict(), 'modelTrans.pth')\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def test(model, testLoader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            images, labels = data\n",
    "            # images = images.view(-1, inputDim)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the network on the {} test images: {:.1f}'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 400] loss: 0.8403193817138672\n",
      "[1, 800] loss: 0.7007005299329758\n",
      "[1] loss: 1.6975333766734346\n",
      "Validation Accuracy:  77.86666666666666\n",
      "[2, 400] loss: 0.6722686799764633\n",
      "[2, 800] loss: 0.6535521035194397\n",
      "[2] loss: 1.6249218786016424\n",
      "Validation Accuracy:  84.63333333333334\n",
      "[3, 400] loss: 0.641171721458435\n",
      "[3, 800] loss: 0.6354814049005508\n",
      "[3] loss: 1.5751493281506477\n",
      "Validation Accuracy:  89.35\n",
      "[4, 400] loss: 0.6322907426357269\n",
      "[4, 800] loss: 0.6279182430505753\n",
      "[4] loss: 1.5621721503582406\n",
      "Validation Accuracy:  90.15\n",
      "[5, 400] loss: 0.624608544588089\n",
      "[5, 800] loss: 0.6230396945476532\n",
      "[5] loss: 1.553807092473862\n",
      "Validation Accuracy:  90.96666666666667\n",
      "[6, 400] loss: 0.6209219110012054\n",
      "[6, 800] loss: 0.6188151051998139\n",
      "[6] loss: 1.5495095037399453\n",
      "Validation Accuracy:  91.31666666666666\n",
      "[7, 400] loss: 0.6185083919763565\n",
      "[7, 800] loss: 0.6172711837291718\n",
      "[7] loss: 1.5374362557492358\n",
      "Validation Accuracy:  92.7\n",
      "[8, 400] loss: 0.6153932087421418\n",
      "[8, 800] loss: 0.614757342338562\n",
      "[8] loss: 1.5406864995652056\n",
      "Validation Accuracy:  92.23333333333333\n",
      "[9, 400] loss: 0.6128403813838958\n",
      "[9, 800] loss: 0.6133739786148071\n",
      "[9] loss: 1.5287661983611736\n",
      "Validation Accuracy:  93.38333333333334\n",
      "[10, 400] loss: 0.6119105079174042\n",
      "[10, 800] loss: 0.6103111603260041\n",
      "[10] loss: 1.5302071152849401\n",
      "Validation Accuracy:  93.1\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 93.7\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train(model3, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model3, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainSize = 5400\n",
    "valSize = 600\n",
    "wasteSize = 54000\n",
    "train_dataset, val_dataset, waste_dataset = random_split(trainset, [trainSize, valSize, wasteSize])\n",
    "trainLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valLoader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "testLoader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2.2811625957489015\n",
      "Validation Accuracy:  18.0\n",
      "[2] loss: 2.2101547479629517\n",
      "Validation Accuracy:  26.833333333333332\n",
      "[3] loss: 2.070841407775879\n",
      "Validation Accuracy:  45.0\n",
      "[4] loss: 1.9706135272979737\n",
      "Validation Accuracy:  51.333333333333336\n",
      "[5] loss: 1.8980331659317016\n",
      "Validation Accuracy:  60.666666666666664\n",
      "[6] loss: 1.8242630243301392\n",
      "Validation Accuracy:  70.5\n",
      "[7] loss: 1.776163387298584\n",
      "Validation Accuracy:  71.33333333333333\n",
      "[8] loss: 1.7163463950157165\n",
      "Validation Accuracy:  79.0\n",
      "[9] loss: 1.6777763962745667\n",
      "Validation Accuracy:  79.83333333333333\n",
      "[10] loss: 1.6806558132171632\n",
      "Validation Accuracy:  80.16666666666667\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 80.1\n"
     ]
    }
   ],
   "source": [
    "model3 = ViT(inputDim, hiddenDim, outputDim, numLayers, nhead)\n",
    "model3 = model3.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.0001)\n",
    "train(model3, criterion, optimizer, epochs, trainLoader, valLoader, device)\n",
    "test(model3, testLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ViT model achieves a high validation and test accuracy when trained with 60K samples, surpassing 90% accuracy. This indicates that the model has effectively learned the representations from the large dataset, leading to strong generalization performance.\n",
    "- With less size of data, VitT is unable to capture the effective representations and generalizations in the data.\n",
    "- The ViT model trained with 6K samples achieves a lower validation and test accuracy compared to the model trained with 60K samples. While the accuracy is still reasonable, it falls short of the performance achieved with a larger dataset.\n",
    "- ViT models, with their self-attention mechanism, are known for their ability to capture long-range dependencies and learn representations effectively. However, this effectiveness is highly dependent on the size and diversity of the training data. With a larger dataset, the ViT model can learn more comprehensive representations, leading to higher accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
